# ğŸ¤– Blogging Agents - AI-Powered Blog Content Generation Service

<div align="center">

![Python](https://img.shields.io/badge/Python-3.13-blue?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green?logo=fastapi&logoColor=white)
![Google Gemini](https://img.shields.io/badge/Google%20Gemini-AI-blue?logo=google&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-Framework-orange?logo=chainlink&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker&logoColor=white)

**Blogging Agents** is an AI-powered content generation service that automates the entire blog writing process. Using advanced AI agents, web search, intelligent scraping, and Google's Gemini AI, it transforms any topic into a professionally written, SEO-optimized blog post.

</div>

---

## ğŸŒŸ What This AI System Does

This service is designed to **create AI-generated blogs automatically**. Given just a topic, the system:

1. **ğŸ” Searches the Web** - Uses DuckDuckGo to find relevant sources
2. **ğŸ“„ Scrapes Content** - Extracts and processes information from multiple websites
3. **ğŸ§  AI Processing** - Uses Google Gemini to analyze, summarize, and generate content
4. **âœ… Fact Verification** - (Deep Research) Cross-references facts with additional searches
5. **âœï¸ Blog Generation** - Creates SEO-optimized, human-like blog content
6. **ğŸ–¼ï¸ Featured Image** - Automatically finds and validates appropriate images
7. **ğŸ“ HTML Output** - Converts Markdown output to clean, sanitized HTML

---

## ğŸš€ Two Research Modes

### âš¡ Quick Research Mode
Fast content generation using a streamlined pipeline:

```
Topic â†’ Web Search â†’ Scrape URLs â†’ Generate Blog â†’ HTML Output
```

- **Best for**: Time-sensitive content, simpler topics
- **Speed**: ~30-60 seconds
- **Pipeline**: LangChain RunnableSequence

### ğŸ”¬ Deep Research Mode
Comprehensive research with fact verification using an intelligent state graph:

```
Topic â†’ Query Planning â†’ Multi-Search â†’ Scrape â†’ Summarize â†’ Verify Facts â†’ Generate Blog â†’ HTML
```

- **Best for**: In-depth articles, complex topics, accuracy-critical content
- **Speed**: ~2-5 minutes
- **Pipeline**: LangGraph StateGraph with 7 nodes

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FastAPI Server                          â”‚
â”‚                        (main.py:8001)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Quick Research â”‚              â”‚     Deep Research        â”‚  â”‚
â”‚  â”‚  (RunnableSeq)  â”‚              â”‚     (LangGraph)          â”‚  â”‚
â”‚  â”‚                 â”‚              â”‚                          â”‚  â”‚
â”‚  â”‚  1. WebSearch   â”‚              â”‚  1. generate_queries     â”‚  â”‚
â”‚  â”‚  2. WebScrape   â”‚              â”‚  2. get_urls             â”‚  â”‚
â”‚  â”‚  3. Generate    â”‚              â”‚  3. scrape_data          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  4. summarized_data      â”‚  â”‚
â”‚           â”‚                       â”‚  5. verify_facts         â”‚  â”‚
â”‚           â”‚                       â”‚  6. generate_blog        â”‚  â”‚
â”‚           â”‚                       â”‚  7. convert_output       â”‚  â”‚
â”‚           â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                     â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                     Shared Tools                          â”‚  â”‚
â”‚  â”‚  â€¢ Search (DuckDuckGo)    â€¢ WebScraper (BS4/newspaper3k)  â”‚  â”‚
â”‚  â”‚  â€¢ FeaturedImageExtractor â€¢ MarkdownToHTML (mistune)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                      â”‚
â”‚                          â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Google Gemini AI Integration                 â”‚  â”‚
â”‚  â”‚         (Structured Output with Pydantic Models)          â”‚  â”‚
â”‚  â”‚    â€¢ gemini-2.0-flash (blog generation)                   â”‚  â”‚
â”‚  â”‚    â€¢ gemini-2.5-flash (summarization, fact verification)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Project Structure

```
blogging_agents/
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚
â”œâ”€â”€ QuickResearch/          # Quick research pipeline
â”‚   â””â”€â”€ quickresearch.py    # LangChain RunnableSequence implementation
â”‚
â”œâ”€â”€ DeepResearch/           # Deep research pipeline  
â”‚   â”œâ”€â”€ deepresearch.py     # LangGraph StateGraph implementation
â”‚   â””â”€â”€ tools.py            # Deep research specific tools
â”‚
â”œâ”€â”€ QueryPlanner/           # AI query planning
â”‚   â””â”€â”€ planner.py          # Generates 5 strategic search queries
â”‚
â”œâ”€â”€ Tools/                  # Shared utility tools
â”‚   â”œâ”€â”€ search.py           # DuckDuckGo search integration
â”‚   â”œâ”€â”€ scraper.py          # Web scraping (BS4 + newspaper3k)
â”‚   â””â”€â”€ featuredimage.py    # Featured image extraction & validation
â”‚
â”œâ”€â”€ Google_Genai/           # Google AI integration
â”‚   â””â”€â”€ googlegenai.py      # Gemini structured output wrapper
â”‚
â”œâ”€â”€ Markdown/               # Content conversion
â”‚   â””â”€â”€ toHTML.py           # Markdown to HTML (mistune + bleach)
â”‚
â”œâ”€â”€ dockerfile              # Container configuration
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ envExample.txt          # Environment variable template
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **API Framework** | FastAPI | Async REST API server |
| **AI Orchestration** | LangChain, LangGraph | Agent pipelines and state management |
| **AI Model** | Google Gemini (2.0-flash, 2.5-flash) | Content generation & analysis |
| **Web Search** | DuckDuckGo (ddgs) | Privacy-focused web search |
| **Web Scraping** | BeautifulSoup4, newspaper3k, readability | Content extraction |
| **Markdown** | Mistune | Markdown parsing |
| **Sanitization** | Bleach | HTML sanitization |
| **Validation** | Pydantic | Data validation & structured output |
| **Server** | Uvicorn | ASGI server |
| **Containerization** | Docker | Deployment |

---

## ğŸ“¡ API Reference

### Health Check
```http
GET /
```

**Response:**
```json
{
  "message": "AI Blogging Agents API is running",
  "status": "healthy"
}
```

### Generate Blog
```http
POST /generate_blog
```

**Request Body:**
```json
{
  "topic": "string (required)",
  "max_results": 10,
  "word_count": 1000,
  "scrape_thumbnail": false,
  "method": "quick"
}
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `topic` | string | Required | The blog topic to research and write about |
| `max_results` | int | 10 | Maximum number of search results to process |
| `word_count` | int | 1000 | Target word count for the generated blog |
| `scrape_thumbnail` | bool | false | Whether to find and include a featured image |
| `method` | string | "quick" | Research method: `"quick"` or `"deep"` |

**Response:**
```json
{
  "blog_data": {
    "title": "SEO-Optimized Blog Title",
    "excerpt": "Compelling excerpt for previews (max 200 chars)",
    "content": "<p>Full HTML-formatted blog content...</p>",
    "tags": ["tag1", "tag2", "tag3"]
  },
  "featured_image": {
    "success": true,
    "image_url": "https://example.com/image.jpg"
  }
}
```

---

## ğŸ§  AI Content Generation Process

### Blog Prompt Engineering

The AI generates content following strict guidelines:

- **Originality**: Rewrites ideas uniquely, never copies
- **Accuracy**: Uses only provided research data
- **Style**: Conversational, authoritative, 12th-grade reading level
- **SEO**: Keywords in title, headings, and first 100 words
- **Structure**: Markdown with proper headings, lists, tables, and code blocks
- **Avoids AI ClichÃ©s**: No "In today's fast-paced world..." or "In conclusion..."

### Generated Output Structure

```typescript
{
  title: string,      // SEO-optimized title
  excerpt: string,    // 200-char max preview
  content: string,    // Full Markdown/HTML content
  tags: string[]      // Up to 10 relevant tags
}
```

---

## ğŸ”§ Deep Research Pipeline (LangGraph)

The Deep Research mode uses a sophisticated state graph:

```mermaid
graph TD
    A[START] --> B[generate_queries]
    B --> C[get_urls]
    C --> D[scrape_data]
    D --> E[summarized_data]
    E --> F[verify_facts]
    F --> G[generate_blog]
    G --> H[convert_output]
    H --> I[END]
```

### State Schema
```python
class BlogState(TypedDict):
    topic: str
    word_count: int
    queries: list[str]           # AI-generated search queries
    urls: list[str]              # Found URLs
    data: list[dict]             # Scraped content
    summarized_results: dict     # Summarized content per source
    facts_to_verify: list[str]   # Key facts needing verification
    verified_facts: list[dict]   # Verified fact results
    title: str
    excerpt: str
    content: str
    tags: list[str]
```

---

## ğŸ” Query Planning (Deep Research)

The QueryPlanner generates 5 strategic search queries covering:

1. **Foundational/Definitional** - Core concepts
2. **How-to/Practical** - Actionable advice
3. **Specific Sub-topics** - Deep dives
4. **Data/Statistics** - Evidence and support
5. **Unique Angles** - Expert opinions, trends, controversies

---

## ğŸ–¼ï¸ Featured Image Extraction

The FeaturedImageExtractor:

- Checks Open Graph (`og:image`) and Twitter Card meta tags
- Scans article content for suitable images
- Validates image format (JPEG, PNG, WebP only)
- Verifies file size (max 5MB)
- Analyzes dimensions for optimal quality
- Skips icons, logos, avatars, and ads

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.13+
- Google AI API Key (Gemini access)

### Installation

```bash
# Clone the repository
git clone https://github.com/HamadKhan345/blogging_agents.git
cd blogging_agents

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
.\venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
echo "GOOGLE_API_KEY=your-google-api-key" > .env
```

### Running the Server

```bash
# Development
uvicorn main:app --host 127.0.0.1 --port 8001 --reload

# Production
uvicorn main:app --host 0.0.0.0 --port 8001 --workers 2
```

The API will be available at `http://localhost:8001`

---

## ğŸ³ Docker Deployment

```bash
# Build the image
docker build -t blogging-agents .

# Run the container
docker run -d \
  -p 8001:8000 \
  -e GOOGLE_API_KEY=your-api-key \
  blogging-agents
```

---

## âš™ï¸ Configuration

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GOOGLE_API_KEY` | Yes | Google AI API key for Gemini access |

### Default Settings

| Setting | Value |
|---------|-------|
| Default Port | 8001 |
| Request Timeout | 10 seconds |
| Max Image Size | 5 MB |
| Scrape Delay | 1 second between requests |
| Max Retries | 4 (for AI generation) |

---

## ğŸ”— Integration with AutoBlog

This service is designed to work as the AI backend for the **AutoBlog** Django application:

1. AutoBlog sends a POST request to `/generate_blog`
2. Blogging Agents researches and generates content
3. Response contains complete blog data ready for publishing
4. AutoBlog creates the blog post in the database

```python
# AutoBlog integration example
payload = {
    'topic': 'Your Blog Topic',
    'max_results': 10,
    'word_count': 700,
    'scrape_thumbnail': True,
    'method': 'quick'  # or 'deep'
}

response = await client.post(
    "http://localhost:8001/generate_blog",
    json=payload,
    timeout=900
)
```

---

## ğŸ“ Example Usage

### Quick Research (Python)
```python
import requests

response = requests.post(
    "http://localhost:8001/generate_blog",
    json={
        "topic": "Benefits of Remote Work in 2025",
        "word_count": 800,
        "method": "quick",
        "scrape_thumbnail": True
    }
)

data = response.json()
print(f"Title: {data['blog_data']['title']}")
print(f"Tags: {data['blog_data']['tags']}")
```

### Deep Research (cURL)
```bash
curl -X POST http://localhost:8001/generate_blog \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "The Future of Artificial Intelligence",
    "word_count": 1500,
    "method": "deep",
    "scrape_thumbnail": true
  }'
```

---

## âš ï¸ Rate Limiting & Best Practices

- **Delay between scrapes**: 1 second (configurable)
- **AI retry with backoff**: 5 seconds between retries
- **Request timeout**: 10 seconds for web requests
- **Respectful scraping**: User-Agent header included

---

## ğŸ”’ Security Features

- HTML sanitization via **Bleach** (XSS prevention)
- Allowed HTML tags whitelist
- Input validation via **Pydantic**
- No persistent data storage (stateless API)

---

## ğŸ“„ License

This project is proprietary software. All rights reserved.

---

<div align="center">

*Automate your content creation with intelligent AI agents*

</div>
